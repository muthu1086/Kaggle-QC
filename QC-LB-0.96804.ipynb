{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xg\n",
    "import time\n",
    "\n",
    "train =pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Splitting Date Column\n",
    "\n",
    "train['Date'] = pd.to_datetime(pd.Series(train['Original_Quote_Date']))\n",
    "train = train.drop('Original_Quote_Date', axis=1)\n",
    "\n",
    "test['Date'] = pd.to_datetime(pd.Series(test['Original_Quote_Date']))\n",
    "test = test.drop('Original_Quote_Date', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "train['Year'] = train['Date'].apply(lambda x: int(str(x)[:4]))\n",
    "train['Month'] = train['Date'].apply(lambda x: int(str(x)[5:7]))\n",
    "train['weekday'] = train['Date'].dt.dayofweek\n",
    "\n",
    "test['Year'] = test['Date'].apply(lambda x: int(str(x)[:4]))\n",
    "test['Month'] = test['Date'].apply(lambda x: int(str(x)[5:7]))\n",
    "test['weekday'] = test['Date'].dt.dayofweek\n",
    "\n",
    "train = train.drop('Date', axis=1)\n",
    "test = test.drop('Date', axis=1)\n",
    "\n",
    "# Imputing with -1\n",
    "\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "\n",
    "# Using One Hot Encoder for Categorical Columns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "for f in train.columns:\n",
    "    if train[f].dtype=='object':\n",
    "        print(f)\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "        test[f] = lbl.transform(list(test[f].values))\n",
    "\n",
    "\n",
    "# Saving Cleaned data        \n",
    "test.to_csv('test-clean.csv',index=False)\n",
    "train.to_csv('train-clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stating to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.8919401169\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train = pd.read_csv('train-clean.csv')\n",
    "test = pd.read_csv('test-clean.csv')\n",
    "\n",
    "y = train.QuoteConversion_Flag.values\n",
    "#quote_no = test.QuoteNumber.values\n",
    "train = train.drop(['QuoteConversion_Flag'], axis=1)\n",
    "#test = test.drop('QuoteNumber', axis=1)\n",
    "\n",
    "train = train.fillna(-1)\n",
    "test = test.fillna(-1)\n",
    "dtrain = xg.DMatrix(train,label=y)\n",
    "dtest = xg.DMatrix(test)\n",
    "elapsed_time = time.time() - start_time\n",
    "print elapsed_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model and save the model so that can reuse it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model 1\n",
    "num_rounds = 1800\n",
    "parm = { 'objective':\"binary:logistic\",'booster':\"gbtree\",'eval_metric':\"auc\",'eta':0.015,'max_depth':7,'subsample':0.83,'colsample_bytree':0.77,'maximize': 'FALSE' ,'seed':1718}\n",
    "plst = parm.items()\n",
    "\n",
    "bst_1 = xg.train( plst,dtrain, num_rounds)\n",
    "bst_1.save_model('model1.model')\n",
    "ypred_1 = bst_1.predict(dtest,ntree_limit=bst_1.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 2\n",
    "num_rounds = 1800\n",
    "parm = { 'objective':\"binary:logistic\",'booster':\"gbtree\",'eval_metric':\"auc\",'eta':0.023,'max_depth':7,'subsample':0.83,'colsample_bytree':0.77,'maximize': 'FALSE' ,'seed':1718}\n",
    "plst = parm.items()\n",
    "\n",
    "bst_2 = xg.train( plst,dtrain, num_rounds)\n",
    "\n",
    "bst_2.save_model('model2.model')\n",
    "ypred_2 = bst_2.predict(dtest,ntree_limit=bst_2.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model 3\n",
    "num_rounds = 2000\n",
    "parm = { 'objective':\"binary:logistic\",'booster':\"gbtree\",'eval_metric':\"auc\",'eta':0.023,'max_depth':7,'subsample':0.83,'colsample_bytree':0.77,'maximize': 'FALSE' ,'seed':1718}\n",
    "plst = parm.items()\n",
    "\n",
    "bst_3 = xg.train( plst,dtrain, num_rounds)\n",
    "bst_3.save_model('model3.model')\n",
    "ypred_3 = bst_3.predict(dtest,ntree_limit=bst_3.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 4\n",
    "num_rounds = 1800\n",
    "parm = { 'objective':\"binary:logistic\",'booster':\"gbtree\",'eval_metric':\"auc\",'eta':0.01,'max_depth':8,'subsample':0.83,'colsample_bytree':0.77,'maximize': 'FALSE' ,'seed':1718}\n",
    "plst = parm.items()\n",
    "\n",
    "bst_4 = xg.train( plst,dtrain, num_rounds)\n",
    "bst_4.save_model('model4.model')\n",
    "ypred_4 = bst_4.predict(dtest,ntree_limit=bst_4.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model 5\n",
    "num_rounds = 1800\n",
    "parm = { 'objective':\"binary:logistic\",'booster':\"gbtree\",'eval_metric':\"auc\",'eta':0.02,'max_depth':7,'subsample':0.75,'colsample_bytree':0.68,'seed':1718}\n",
    "plst = parm.items()\n",
    "\n",
    "bst_5 = xg.train( plst,dtrain, num_rounds)\n",
    "bst_5.save_model('model5.model')\n",
    "ypred_5 = bst_5.predict(dtest,ntree_limit=bst_5.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 6\n",
    "num_rounds = 1700\n",
    "parm = { 'objective':\"binary:logistic\",'booster':\"gbtree\",'eval_metric':\"auc\",'eta':0.023,'max_depth':8,'subsample':0.75,'colsample_bytree':0.68,'seed':6666}\n",
    "plst = parm.items()\n",
    "\n",
    "bst_6 = xg.train( plst,dtrain, num_rounds)\n",
    "bst_6.save_model('model6.model')\n",
    "ypred_6 = bst_6.predict(dtest,ntree_limit=bst_6.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 7\n",
    "num_rounds = 1800\n",
    "parm = { 'objective':\"binary:logistic\",'booster':\"gbtree\",'eval_metric':\"auc\",'eta':0.023,'max_depth':6,'subsample':0.83,'colsample_bytree':0.77,'maximize': 'FALSE','seed':1718}\n",
    "plst = parm.items()\n",
    "\n",
    "bst_7 = xg.train( plst,dtrain, num_rounds)\n",
    "bst_7.save_model('model7.model')\n",
    "ypred_7 = bst_7.predict(dtest,ntree_limit=bst_7.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 8\n",
    "num_rounds = 2000\n",
    "parm = { 'objective':\"binary:logistic\",'booster':\"gbtree\",'eval_metric':\"auc\",'eta':0.01,'max_depth':8,'subsample':0.75,'colsample_bytree':0.68,'maximize': 'FALSE','seed':1718}\n",
    "plst = parm.items()\n",
    "\n",
    "bst_8 = xg.train( plst,dtrain, num_rounds)\n",
    "bst_8.save_model('model8.model')\n",
    "ypred_8 = bst_8.predict(dtest,ntree_limit=bst_8.best_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Will Run below cell form saved model if i dont have time waiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst_1 = xg.Booster({'nthread':4}) #init model\n",
    "bst_1.load_model(\"model1.model\")\n",
    "ypred_1 = bst_1.predict(dtest)\n",
    "\n",
    "bst_2 = xg.Booster({'nthread':4}) #init model\n",
    "bst_2.load_model(\"model2.model\")\n",
    "ypred_2 = bst_2.predict(dtest)\n",
    "\n",
    "bst_3 = xg.Booster({'nthread':4}) #init model\n",
    "bst_3.load_model(\"model3.model\")\n",
    "ypred_3 = bst_3.predict(dtest)\n",
    "\n",
    "bst_4 = xg.Booster({'nthread':4}) #init model\n",
    "bst_4.load_model(\"model4.model\")\n",
    "ypred_4 = bst_4.predict(dtest)\n",
    "\n",
    "bst_5 = xg.Booster({'nthread':4}) #init model\n",
    "bst_5.load_model(\"model5.model\")\n",
    "ypred_5 = bst_5.predict(dtest)\n",
    "\n",
    "\n",
    "bst_6 = xg.Booster({'nthread':4}) #init model\n",
    "bst_6.load_model(\"model6.model\")\n",
    "ypred_6 = bst_6.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensambling the predicted values, not using weighted ensamble will try later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted = (ypred_1 + ypred_2 + ypred_3 + ypred_4 + ypred_5 + ypred_6 + ypred_7 ) / 7\n",
    "\n",
    "test[\"QuoteConversion_Flag\"]=predicted\n",
    "test.to_csv('Submit-ensamble-7-model.csv',columns=['QuoteNumber','QuoteConversion_Flag'],index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
